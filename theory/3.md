# Many to one

## Many to one

- 자연어 처리 분야
  - 어떤 문장 or 단어를 RNN 으로 인코딩하고
  - 해당문장 또는 단어의 sentiment를 classification 하는데 활용

### Sequence classification

- This movie is good
- sentence를 word단위로 Tokenization 하면
- This, movie, is, good
- Classification 진행
- Positive

### How?

- 토큰인 word(단어) 는 어떤 숫자가 아니기 때문에 RNN 으로 처리 불가
- 토큰을 numeric vector로 바꾸어주는 연산을 담당하는 `Embedding layer` 가 존재합니다.
  - 각각의 토큰을 RNN이 쓸수 있도록 바꾸어 줍니다.

### Word sentiment classification

- RNN을 구현할 때 데이터가 서로 다른 시퀀스의 length를 가진경우 길이를 맞추기 위해서 pad와 같은 특별한 토큰을 도입하여 데이터의 시퀀스를 맞추어 줍니다.

#### model

```
# creating simple rnn for "many to one" classification

input_dim = len(char2idx)
output_dim = len(char2idx)
one_hot = np.eye(len(char2idx))
hidden_size = 10
num_classes = 2

model = Sequential()
model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,
                           trainable=False, mask_zero=True, input_length=max_sequence,
                           embeddings_initializer=keras.initializers.Constant(one_hot)))
model.add(layers.SimpleRNN(units=hidden_size))
model.add(layers.Dense(units=num_classes))
```

- Embedding layer 는 token 을 one hot vector로 표현
- mask_zero = True : 전처리단계에서 0값으로 padding된 부분을 연산에서 제외
- trainable = False : one hot vector를 training하지 않습니다.

- embedding layer : (data dimension, max sequence, input_dim)
- RNN : hidden size
- Dense : Classification