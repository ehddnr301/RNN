# many to many bidirectional

## bidriectional

- RNN 은 단방향으로만 활용됩니다.

  - 첫번째 토큰은 1개의 정보
  - 두번째 토큰은 2개의 정보
  - 세번째 토큰은 3개의 정보 이렇게 생각할수 있습니다.
    - 정보 불균형이 일어납니다.

- 시퀀스를 두 방향으로 읽습니다.

  - foward RNN
  - backward RNN
  - 정보양이 균형적입니다.

- embedding layer를 활용하여 각각의 토큰을 `numeric vector`로 변환합니다.
- RNN 에서는 one hot vector만 사용했습니다.

- forward RNN 의 hidden states
- backward RNN 의 hidden states 를 합쳐 concatenate 하는 방식으로 새로운 벡터를 생성

- loss 는 sequence loss 를 계산합니다.
