# RNN

## Sequence data

- 연속적인 data형태
- 우리는 문장을 한 단어로만 이해하지 않습니다.
- 이전단어 + 현재 단어를 합쳐 문장을 이해합니다 (time series)
- NN/CNN 은 할 수 없는 일입니다.

- 다음것을 계산하는데 이전의 연산이 영향을 미치는 모델 RNN

## RNN 계산

- (newState) = f(oldState, inputVector)
- h_t = f_w(h_t-1, x_t)

### Vanilla RNN

- h_t = tanh(W_hh h_t-1 + W_xh x_t)
  - 이전 state에서 오는 입력 h_t-1 에 대한 가중치 : W_hh
  - 이번 state에서의 입력 x_t 에 대한 가중치 : W_xh
- y_t = W_hy h_t
  - y를 뽑아내기위한 가중치 : W_hy

- 여기서 전체 셀이 모두 같은 값을 사용한다.
  - W_hh , W_xh, W_hy 는 각각 셀에서 모두 같은 값을 사용한다.

## model example

- onehot encoding
  - h : 1 0 0 0
    -  첫번째 입력 & 가중치 W_xh 
    -  (h_t-1 = 0)
    -  결과를 뽑아 낼때 가중치 W_hy
    -  `결과 = [1, 2.2, -3, -4]`
    -  softmax 써서 뽑아내서
    -  다음을 예측하면 e
  - e : 0 1 0 0
    -  두번째 입력 & 가중치 W_xh
    -  h_t-1 = 첫번째 state & 가중치 W_hh
    -  결과를 뽑아 낼때 가중치 W_hy
    -  다음을 예측하면 l
  - l : 0 0 1 0
  - l : 0 0 1 0
  - o : 0 0 0 1

## RNN 활용

- Language Model
- Speech Recognition
- Machine Translation
- Conversation Modeling / Question Answering
- Image Video caption

## RNN 형태

- one to one
- one to many : 하나의 입력 & 여러 출력
- many to one : 여러 입력 & 하나의 출력
- many to many : 여러 입력 & 여러 출력

- multi layer 형태도 가능합니다!