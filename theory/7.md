# seq to seq

- 번역이나 챗봇에 이용됩니다.

## Seq to Seq

-

## Data pipeline

sources = [['I', 'feel', 'hungry'],
['tensorflow', 'is', 'very', 'difficult'],
['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],
['tensorflow', 'is', 'very', 'fast', 'changing']]
targets = [['나는', '배가', '고프다'],
['텐서플로우는', '매우', '어렵다'],
['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],
['텐서플로우는', '매우', '빠르게', '변화한다']]

- 와 같은 형태입니다.

### 전처리 과정

- 소스 와 타겟으로 나눕니다.
  - 소스
  - 타겟
    - 타겟에서의 입력으로 사용될 입력을 만드는 전처리 과정과 결과로 학습을 위해 필요한 라벨인 타겟값을 만들어야합니다.
    - 타겟의 입력값에는 문장과 시작 값 끝에 `시작과 종료 토큰`을 넣는다.
    - 타겟의 라벨 값에는 문장 끝에 `종료 토큰`을 붙여 전처리합니다.

## Encoder-Decoder

- RNN 모델을 기반으로 하여 모델을 크게 인코더 & 디코더 로 나눕니다.

  - 인코더 : 입력정보를 담은 벡터를 만들어냅니다.
    - RNN step 마다 입력이 들어갑니다.
    - 신경망 마지막 부분에 하나의 벡터값이 나옵니다.
  - 디코더 : 이 벡터를 활용해 재귀적으로 출력값을 만듭니다.
    - 인코더의 마지막 부분의 hidden 벡터값 으로 학습합니다.
    - 각 스텝의 출력값이 다음 스텝의 입력값으로 사용됩니다.

- 인코더
  - 안녕
  - 오랜만이야
  - padding
  - padding
- 디코더
  - 그래 : 다음스텝의 입력값으로 사용됩니다.
  - 오랜만이야 : 그래를 받아서 사용합니다.

## Train

- GPU 가 있다면 CuDNNGRU

### Teacher forcing

- I feel hungry

bos : 시작토큰

#### Without Teacher forcing

- X 가 [bos] 가 주어졌다면 Y 의 예측값이 a 가 나왔다고 가정해봅시다.
  - 원래는 I 가 나와야 정상입니다.
- bos 토큰 이후 Y가 잘못예측한 a가 들어간다면 모델에 패널티를 부여합니다. ( 학습 )

#### With Teacher forcing

- Y가 어떤 값을 예측하건 간에 bos토큰 다음으로 정답인 I와 feel 이 들어갑니다.
